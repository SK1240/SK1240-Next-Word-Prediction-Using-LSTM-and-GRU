# ğŸ“ Next Word Prediction using LSTM & GRU
A sleek and educational implementation of **next-word prediction** powered by two advanced **Recurrent Neural Network (RNN)** architectures â€” **Long Short-Term Memory (LSTM)** and **Gated Recurrent Unit (GRU)**.

This project combines **deep learning** and **natural language processing (NLP)** to predict the most likely next word in a given phrase.

It includes **Streamlit**-based **web applications** for **real-time text inference**, **pretrained models**, and interactive training notebooks for further experimentation.

## ğŸš€ Project Highlights

| Feature                    | Description                                                                  |
| -------------------------- | ---------------------------------------------------------------------------- |
| ğŸ§© **Dual Models**         | **LSTM** and **GRU** architectures implemented for comparative next-word prediction. |
| ğŸ’» **Interactive Apps**    | **Two Streamlit applications** for hands-on testing of the models.               |
| ğŸ§  **Pretrained Models**   | Ready-to-use `.h5` model files and corresponding `tokenizer.pkl` tokenizer.   |
| ğŸ“˜ **Notebooks Included**  | Full training and retraining workflows for both models.                      |
| ğŸ”„ **End-to-End Pipeline** | Text preprocessing â†’ tokenization â†’ prediction â†’ decoding.                   |
